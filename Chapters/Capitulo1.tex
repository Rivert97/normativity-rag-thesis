\chapter{Introducción}

Todas las organizaciones requieren un conjunto de normas para funcionar adecuadamente.
Si bien, en algunas organizaciones, las normas se dan a conocer de forma verbal,
las organizaciones constituidas formalmente requieren que sus lineamientos se encuentren
redactados en documentos para evitar errores o ambigüedades en la
aplicación de los mismos.

En organizaciones grandes, los documentos normativos suelen ser extensos y poseer un
lenguaje que no es familiar para todos los miembros, lo cual puede dificultar el
entendimiento completo de las normas.

Por otro lado, en la última década, se han presentado avances significativos
en lo que popularmente se conoce como \textit{Inteligencia Artificial}, tratándose
específicamente de una mejora notable en los modelos de lenguaje, que ahora
permiten a los sistemas computacionales comunicarse con los usuarios empleando
lenguaje natural y desempeñar tareas relacionadas con la interpretación de texto.

Con el objetivo de aprovechar estas herramientas y favorecer a la comunidad
universitaria, surge el propósito de proveer una herramienta que ayude a conocer
y entender la normativa de la Universidad de Guanajuato. Para ello, se emplearán
técnicas modernas de procesamiento de texto para crear un asistente virtual,
tipo chatbot, que tenga la capacidad de resolver dudas acerca de la los
documentos normativos de la universidad de forma fundamentada, y así, evitar
la vulneración de los derechos de la comunidad y evitar omisiones en el
cumplimiento de sus obligaciones.

\section{Justificación}

La normatividad vigente de la Universidad de Guanajuato (UG) se puede consultar
en su página oficial \footnote{https://www.ugto.mx/}, en la cual se presentan
22 documentos de solo texto en formato PDF que, en conjunto, pesan 6.9 MB. Si
se convierten estos documentos a texto plano, se obtienen 1.1 MB de información,
lo que equivale a 168,011 palabras. Además, la página web presenta otros documentos
relevantes como el Plan de Desarrollo Institucional, la Gaceta Universitaria,
entre otros, los cuales abonan a la cantidad de textos que se espera que
alumnos, docentes y administrativos conozcan y den seguimiento a sus actualizaciones.

Sin embargo, una dificultad que se presenta al momento de divulgar documentos de carácter
oficial es la falta de cultura lectora en la sociedad mexicana. Según
datos del MOLEC 2024 (Módulo de lectura del INEGI) \cite{inegi_modulo_2024},
el porcentaje de población lectora disminuyó 14.6 puntos porcentuales en los últimos
nueve años, pasando del 84.2 \% en 2015 al 69.6 \% en 2024. Aunque se observa
una leve mejora de la cantidad de población lectora con respecto a 2023 (68.5 \%),
la falta de hábitos de lectura en la población es notable. De aquí se
presenta la necesidad de proponer estrategias alternativas en la divulgación de documentos
normativos, como puede ser el uso de asistentes inteligentes.

Por otra parte, el Foro Económico Mundial 2020 (WEF) presentó el concepto de
Educación 4.0 \cite{world_economic_forum_schools_2020}, en la cual se reconoce que la
educación debe adaptarse a las necesidades del futuro y para ello el UNESCO-UNEVOC
(Centro internacional para la Educación y Formación Técnica y Profesional)
define la Educación 4.0 como una técnica de aprendizaje que se centra en
transformar la educación con el uso de tecnologías avanzadas, reconociendo la
Inteligencia Artificial como una de ellas. Alineado con esta visión, este proyecto
pretende servir como ejemplo de la integración de la inteligencia artificial en
el ámbito educativo, para resolver una de las necesidades de la comunidad. Así
mismo, ayudará a fomentar el uso responsable de las tecnologías como los chatbots
inteligentes al emplearlos como herramientas de apoyo en la interpretación de
documentos normativos.

Aunado a lo anterior, desde la introducción de ChatGPT en 2022 \cite{openai_introducing_2022},
los modelos de lenguaje con capacidades conversacionales, o chatbots inteligentes,
se han integraron en diversos ámbitos de la vida cotidiana, siendo el ámbito
académico uno de los más influenciados. Estos cambios motivan a los investigadores
a analizar el impacto que tienen estas herramientas en la educación, como es el
caso de Peláez-Sánchez et al. \cite{pelaez-sanchez_impact_2024}.
Así mismo, se introduce la incógnita de los usos se les puede dar a estas herramientas en
beneficio de la comunidad académica, siendo ésta la motivación del presente proyecto.

Si bien en el mercado actual existen chatbots inteligentes que pueden
responder preguntas relacionadas a documentos que les sean proporcionados, es
difícil proporcionarles todo el contexto necesario para que sus respuestas sean
correctas, que provengan de fuentes autorizadas y estén debidamente
referenciadas. Además, estas herramientas comerciales tienen desventajas
marcadas como que suelen estar sujetas a políticas de uso o privacidad que pueden
ser desfavorables para los usuarios, puede haber variaciones
en su costo, el nivel de personalización es limitado y generalmente se desconoce
el uso que se les da a los datos confidenciales que se comparten en ellas. Lo anterior
obliga a considerar opciones de código abierto, con las que se puede alcanzar
un nivel de personalización mayor, mejor control sobre las políticas de privacidad
y garantizar la continuidad del sistema con un plan adecuado de mantenimiento
y actualización. Es bajo esta filosofía que este proyecto pretende crear un sistema
adaptado a las necesidades de los usuarios y que funcione con opciones de código
abierto.

\section{Antecedentes}

El Procesamiento de Lenguaje Natural (NLP, Natural Language Processing) es una rama
de la inteligencia artificial y la lingüística, dedicada a dotar a las computadoras
de entendimiento de frases o  palabras escritas en lenguajes humanos \cite{khurana_natural_2023}.
En este proyecto, intervienen diferenes áreas del NLP, como son el modelado de lenguaje
(LM, Language Modeling), la respuesta a preguntas (QA, Question Answering) y la
similitud semántica de texto (STS, Semantic Textual Similarity), por mencionar
las más importantes.

Respecto al modelado de lenguaje, es el área del NLP que pretende predecir la siguiente palabra o carácter en una
secuencia de texto dada. En las úlitmas décadas, se han presentado avances significativos
como son: el modelo neuronal probabilístico de Bengio et al. \cite{bengio_neural_2003}
que empleaba una red neuronal y una tabla de búsqueda para predecir el siguiente carácter;
el uso de redes neuronales entrenadas de forma semisupervisada para aprendizaje
multitarea propuesto por Collobert \& Weston \cite{collobert_unified_2008}; la
introducción de embeddings para aprender representaciones vectoriales distribuidas
de las palabras por Mikolov et al. \cite{mikolov_distributed_2013};
la aparición de los modelos sequence-to-sequence que empleaban Memoria a
Largo Corto-Plazo (LSTM) para convertir una secuencia de texto en otra por
Sutskever et al \cite{sutskever_sequence_2014}; la mejora de los modelos
codificador-decodificador empleando mecanismos de atención para detectar partes de la
oración que son relevantes por parte de Bahdanau et al. \cite{bahdanau_neural_2016};
y por último, la introducción de los transformers, los cuales
son una arquitectura de red neuronal basada únicamente en mecanismos de atención
\cite{vaswani_attention_2017} que alcanzaron excelentes resultados en tareas de traducción
máquina. Es en este proceso que surgen los Modelos de Lenguaje de Gran Tamaño
(LLM, Large Language Models), los cuales emplean técnicas de aprendizaje profundo,
particularmente arquitecturas basadas en transformers, para aprender y entender
patrones complejos y estructuras presentes en los datos.

Estos avances llevaron a la creación del Transformer Generativamente Preentrenado
(GPT) por Radford et al. \cite{radford_improving_2018}, una arquitectura basada en
transformers, acompañada de método de entrenamiento que consiste en preentrenar un modelo de
lenguaje para predecir la siguiente palabra, empleando un corpus de texto sin
etiquetar, seguido de un ajuste fino en tareas específicas. Con esta técnica,
fue posible alcanzar resultados superiores al estado del arte en
diversas tareas de NLP, como son la inferencia de lenguaje natural,
dar respuesta a preguntas, búsquedas por similitud semántica, entre otras.

La presentación del modelo GPT fue seguida de mejoras que incluyeron conjuntos de
entrenamiento más extensos, cambios en las técnicas de ajuste fino, incremento en
el tamaño del modelo, entre otras, dando como resultado el lanzamiento de
ChatGPT-3 \cite{openai_introducing_2022}, definido como un modelo que interactúa de forma
conversacional con capacidad de responder preguntas de seguimiento, admitir sus
errores, objetar premisas incorrectas y rechazar peticiones inapropiadas. Tras
la liberación de ChatGPT-3 al público, múltiples empresas y organizaciones han
empleado metodologías de entrenamiento similares para desarrollar sus propios
modelos conversacionales y competir en el mercado.

Estos modelos conversacionales caen en la categoría de chatbots, los cuales se
definen como sistemas computacionales inteligentes con capacidades de conversación,
que son diseñados para emular una conversación humana con el objetivo de
proporcionar orientación o apoyo \cite{caldarini_literature_2022}.

En la actualidad, los modelos generativos basados en transformers como Chat GPT-4
(OpenAI), Gemini (Google), Llama (Meta), DeepSeek (DeepSeek), entre otros, son el
estado del arte en cuanto a chatbots multidominio, ya que pueden responder preguntas
y realizar tareas en diferentes dominios de conocimiento, siendo algunos de ellos
también multimodales. Estos modelos cuentan con varias versiones y tamaños, para
ajustarse a las necesidades de sus usuarios, algunos siendo de paga y otros de
código abierto.

En el ámbito educativo los LLMs han tenido un impacto significativo,
gracias a sus capacidades de generar resúmenes, resaltar partes
importantes de textos, apoyar en tareas de escritura y en general proveer información
a los estudiantes de temas específicos, además de servir a los profesores a generar
material de apoyo personalizado, ayudar en la planeación de las lecciones o para
calificar pruebas de forma semiautomática \cite{kasneci_chatgpt_2023}.

En el ámbito legal se ha explorado el uso de LLMs para apoyar a profesionales
en ley, impuestos y finanzas, como es el caso de la plataforma Harvey.
Esta empresa, a través de una alianza con OpenAI, entrenó un LLM con conocimiento
legal e historial de casos reales, para generar una herramienta tipo chatbot
que puede contestar preguntas teóricas, citar eventos reales y, en general,
funcionar como asistente en la integración y revisión
de casos complejos \cite{openai_customizing_2024}.

En cuanto a las otras áreas del NLP, la presentación del transformer también
derivó en la creación de arquitecturas como BERT (Bidirectional Encoder
Representations from Transformers), presentada por Devlin et al.
\cite{devlin_bert_2019}, la cual tuvo como objetivo generar representaciones
bidireccionales profundas de texto con el objetivo de usarlas en un posterior
proceso de ajuste fino para tareas más específicas, alcanzando resultados
superiores al estado del arte en tareas como la similitud semántica de texto.
Posteriores modificaciones y alternativas a esta arquitectura fueron presentadas
como son el modelo SBERT (Sentence BERT) de Riemers \& Gurevych
\cite{reimers_sentence-bert_2019}, MiniLM de Wang et al \cite{wang_minilm_2020}
o Qwen3 de Zhang et al. \cite{zhang_qwen3_2025} que han demostrado buenos
resultados en tareas de similitud semántica de texto y respuesta a preguntas.

Los modelos mencionados anteriormente hacen uso de diferentes técnicas de ajuste
para obtener los resultados esperados en tareas específicos, de forma general
(y relacionado a este proyecto), las más comunes son: ingeniería de
prompts y el ajuste fino.

La ingeniería de prompts pretende modificar la forma en que un modelo, entrenado
para ello, emita su respuesta a través de instrucciones que se le proporcionan
en forma de texto. Un ejemplo de aplicación de esta técnica se puede ver en el
trabajo de Patil et al. \cite{patil_prompt_2024} que usó instrucciones para
guiar a los modelos a generar explicaciones amigables para los pacientes sobre
conceptos médicos, enfermedades y opciones de tratamiento, con el fin de
reducir la brecha de conocimientos entre médicos y pacientes.

Por otra parte, el ajuste fino es un proceso en el que un modelo preentrenado,
como un LLM, es reentrenado en un conjunto de datos específico para adaptarlo a
tareas o dominios especializados. Dentro de esta metodología existen dos técnicas
ampliamente usadas: Supervised fine-tuning y Reinforcement Learning From Human
Feedback \cite{anisuzzaman_fine-tuning_2025}. Ambas metodologías emplean técnicas
para ajustar el comportamiento del modelo a casos específicos de uso y dotarlo de
comportamientos enfocados en tareas específicas.

Por último, los modelos de lenguaje usualmente enfrentan problemas como las
alucinaciones, la desactualización del conocimiento y la falta de transparencia y
trazabilidad de su proceso de razonamiento. Con el objetivo de aliviar estos
problemas se desarrollaron las técnicas de recuperación-generación aumentada de
información o generación aumentada por recuperación (RAG, Retrieval-Augmented
Generation). Las técnicas RAG consisten en mejorar los LLMs al extraer
fragmentos de información relevante de bases de conocimiento externas, a través
de cálculos de similitud semántica.
Por ejemplo, en una investigación realizada en el ámbito de la medicina, se
encontró que el uso de RAGs en conjunto con LLMs puede mejorar hasta un 39.7 \%
la exactitud en las respuestas de preguntas relacionadas a las normas de la
American Academy of Orthopaedic Surgeons (AAOS), para la atención a lesiones
del ligamento cruzado anterior \cite{woo_custom_2025}.

\section{Objetivos}

\subsection{Objetivo General}

Desarrollar un asistente virtual tipo chatbot, alojado en la nube, que responda
preguntas sobre la normativa de la Universidad de Guanajuato, implementando cuatro
flujos de trabajo: extracción de información con RAGs, reentrenamiento de LLMs,
backend y frontend. Los cuatro flujos de trabajo emplearán técnicas y herramientas
de CI/CD y MLOps o DevOps (según sea el caso) para el despliegue continuo y
actualización del sistema.

\subsection{Objetivos específicos}

\begin{itemize}
      \item Implementar un algoritmo de extracción de información de documentos
            normativos de la universidad de Guanajuato basado en técnicas RAG, que
            pueda interactuar con un modelo LLM.
      \item Reentrenar un LLM que se comunique con el algoritmo de extracción de
            información, para que sea capaz de interpretar la normativa de la Universidad
            de Guanajuato y contestar preguntas relacionadas de forma especializada y
            personalizada, proporcionando referencias de dónde se obtiene la información.
      \item Desarrollar una API, empleando FastAPI o una tecnología similar,
            para comunicar una aplicación cliente con el modelo.
      \item Desarrollar una aplicación web tipo chatbot, empleando React o una
            tecnología similar, para que un usuario pueda hacer consultas al modelo a
            través de internet.
      \item Implementar un flujo de trabajo para el algoritmo de extracción de
            información que permita la actualización automática o semisupervisada de
            la nueva normativa.
      \item Implementar un flujo de trabajo, utilizando herramientas de MLOps,
            para el reentrenamiento, actualización y despliegue del LLM de forma automática
            o semisupervisada.
      \item Implementar un flujo de trabajo para la API y uno para la aplicación
            web, que emplee técnicas y herramientas de CI/CD y DevOps para desplegar
            actualizaciones de forma automática o semisupervisada.
\end{itemize}

\section{Hipótesis del trabajo}

Es posible emplear recuperación-generación aumentada de información con información
de un dominio específico y limitado, así como reentrenar un modelo de lenguaje
para que pueda proporcionar información y resolver dudas que sean entendibles
por personas sin conocimiento previo. La información que se emplee puede
actualizarse con documentos recientes y el modelo puede reentrenarse para mejorar
la calidad de las respuestas basándose en la interacción con los usuarios. Además,
esta metodología puede aplicarse con diferentes fuentes de información, siempre
que se ajuste el modelo al ámbito deseado.
